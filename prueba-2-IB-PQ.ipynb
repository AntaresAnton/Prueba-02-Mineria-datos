{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Selección de API y Definición del Problema\n",
    "\n",
    "## API Seleccionada\n",
    "- **Nombre**: Disease.sh API\n",
    "- **Endpoint**: `https://disease.sh/v3/covid-19/countries`\n",
    "- **Tipo de datos**: Estadísticas COVID-19 por país\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema de Negocio\n",
    "El objetivo principal es desarrollar un sistema predictivo para anticipar brotes de COVID-19 en diferentes regiones geográficas, permitiendo a los sistemas de salud prepararse adecuadamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manipulación y análisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Análisis estadístico\n",
    "from scipy import stats\n",
    "\n",
    "# Librerías de visualización\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Peticiones API\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extracción de Datos\n",
    "def obtener_datos_covid():\n",
    "    url = \"https://disease.sh/v3/covid-19/countries\"\n",
    "    respuesta = requests.get(url)\n",
    "    return respuesta.json()\n",
    "\n",
    "# Obtener y transformar datos\n",
    "datos = obtener_datos_covid()\n",
    "df = pd.json_normalize(datos)\n",
    "\n",
    "# Guardar en CSV\n",
    "df.to_csv('datos_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores faltantes\n",
    "print(\"Valores faltantes:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas características\n",
    "df['tasa_mortalidad'] = (df['deaths'] / df['cases']) * 100\n",
    "df['tasa_recuperacion'] = (df['recovered'] / df['cases']) * 100\n",
    "df['tasa_positividad'] = (df['cases'] / df['tests']) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Análisis Exploratorio de Datos\n",
    "\n",
    "# Gráfico 1: Top 10 países por casos totales\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_10_casos = df.nlargest(10, 'cases')\n",
    "sns.barplot(data=top_10_casos, x='country', y='cases')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Top 10 Países por Casos Totales de COVID-19')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las 10 variables más relevantes para COVID-19\n",
    "variables_relevantes = [\n",
    "    'cases',\n",
    "    'deaths', \n",
    "    'recovered',\n",
    "    'active',\n",
    "    'critical',\n",
    "    'casesPerOneMillion',\n",
    "    'deathsPerOneMillion',\n",
    "    'tests',\n",
    "    'testsPerOneMillion',\n",
    "    'population'\n",
    "]\n",
    "\n",
    "# Crear matriz de correlación con las variables seleccionadas\n",
    "matriz_correlacion = df[variables_relevantes].corr()\n",
    "\n",
    "# Generar mapa de calor mejorado\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(matriz_correlacion, \n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            linewidths=0.5,\n",
    "            fmt='.2f',\n",
    "            square=True)\n",
    "\n",
    "plt.title('Mapa de Calor: Correlaciones entre Principales Métricas COVID-19')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gráfico 3: Casos por Millón por Continente\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='continent', y='casesPerOneMillion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribución de Casos por Millón por Continente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gráfico 3: Casos por Millón por Continente\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='continent', y='casesPerOneMillion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribución de Casos por Millón por Continente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 4: Dispersión de Pruebas vs Casos por continente\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df, x='testsPerOneMillion', y='casesPerOneMillion', \n",
    "                hue='continent', alpha=0.6)\n",
    "plt.title('Pruebas por Millón vs Casos por Millón por Continente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de valores atípicos usando Z-score\n",
    "def detectar_atipicos(df, columna):\n",
    "    z_scores = stats.zscore(df[columna])\n",
    "    atipicos = df[abs(z_scores) > 3]\n",
    "    return atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar atípicos en casos\n",
    "casos_atipicos = detectar_atipicos(df, 'cases')\n",
    "print(\"\\nValores atípicos en casos totales:\")\n",
    "print(casos_atipicos[['country', 'cases']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas resumen\n",
    "print(\"\\nEstadísticas Resumen:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Construcción de Modelos Predictivos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos\n",
    "# Seleccionamos features relevantes para predecir casos\n",
    "X = df[['population', 'testsPerOneMillion', 'deathsPerOneMillion', 'recovered']]\n",
    "y = df['cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, asegurémonos de tener las versiones correctas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Implementación de modelos con parámetros específicos\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Implementación de validación cruzada manual\n",
    "results = {}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Entrenamiento inicial\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predicciones en conjunto de prueba\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Validación cruzada manual\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "        X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_cv_train, y_cv_train)\n",
    "        y_cv_pred = model.predict(X_cv_val)\n",
    "        cv_scores.append(r2_score(y_cv_val, y_cv_pred))\n",
    "    \n",
    "    results[name]['CV_Score'] = np.mean(cv_scores)\n",
    "\n",
    "# Mostrar resultados\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nResultados para {model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nResultados para {model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configuración del estilo de seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Visualización del árbol con colores personalizados\n",
    "plot_tree(tree_model, \n",
    "          feature_names=feature_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10,\n",
    "          max_depth=3,  # Limitamos profundidad para mejor visualización\n",
    "          class_names=['Casos COVID'])\n",
    "\n",
    "plt.title('Árbol de Decisión para Predicción de Casos COVID-19', fontsize=16, pad=20)\n",
    "\n",
    "# Importancia de características\n",
    "plt.figure(figsize=(10,6))\n",
    "importances = pd.DataFrame({\n",
    "    'features': feature_names,\n",
    "    'importance': tree_model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(data=importances, \n",
    "            x='importance', \n",
    "            y='features',\n",
    "            palette='viridis')\n",
    "plt.title('Importancia de Variables en el Árbol de Decisión', fontsize=12)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Variables')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
